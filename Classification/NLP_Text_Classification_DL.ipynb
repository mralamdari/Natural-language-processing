{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/NLP-Text_Classification/blob/main/NLP_Text_Classification_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnsJJZQtGlSD"
      },
      "outputs": [],
      "source": [
        "!pip install wget\n",
        "!pip install ktrain\n",
        "!pip install pytorch_pretrained_bert pytorch-nlp\n",
        "!pip install tqdm\n",
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "630QbPyVAtxb"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import bs4\n",
        "import tqdm\n",
        "import wget\n",
        "import nltk\n",
        "import shap\n",
        "import torch\n",
        "import ktrain\n",
        "import tarfile\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from ktrain import text\n",
        "from sklearn import base\n",
        "from zipfile import ZipFile\n",
        "from sklearn import metrics\n",
        "from sklearn import pipeline\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "###IMDB Dataset"
      ],
      "metadata": {
        "id": "WqulR4UnPROu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P DATAPATH http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip DATAPATH/glove.6B.zip -d DATAPATH/glove.6B\n",
        "\n",
        "!wget -P DATAPATH http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xvf DATAPATH/aclImdb_v1.tar.gz -C DATAPATH\n",
        "BASE_DIR = 'Data'"
      ],
      "metadata": {
        "id": "J0J-IuZYR9hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWnjSL62GE6T"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = '/content/DATAPATH'\n",
        "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')\n",
        "TRAIN_DATA_DIR = os.path.join(BASE_DIR, 'aclImdb/train')\n",
        "TEST_DATA_DIR = os.path.join(BASE_DIR, 'aclImdb/test')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "metadata": {
        "id": "ViVnx40MI2UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(data_dir):\n",
        "  texts = []\n",
        "  labels_index = {'pos': 1, 'neg': 0}\n",
        "  labels = []\n",
        "  for name in sorted(os.listdir(data_dir)):\n",
        "    path = os.path.join(data_dir, name)\n",
        "    if os.path.isdir(path):\n",
        "      if name=='pos' or name=='neg':\n",
        "        label_id = labels_index[name]\n",
        "        for fname in sorted(os.listdir(path)):\n",
        "          fpath = os.path.join(path, fname)\n",
        "          text = open(fpath, encoding='utf8').read()\n",
        "          texts.append(text)\n",
        "          labels.append(label_id)\n",
        "  return texts, labels"
      ],
      "metadata": {
        "id": "mfEdc3vIPemc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, train_labels = get_data(TRAIN_DATA_DIR)\n",
        "test_texts, test_labels = get_data(TEST_DATA_DIR)\n",
        "\n",
        "labels_index = {'pos': 1, 'neg': 0}"
      ],
      "metadata": {
        "id": "uwcwvh8lQ-xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts[20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cp9FipkLpROx",
        "outputId": "550fde9e-f906-4624-d913-4b6f911b936d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The characters are unlikeable and the script is awful. It's a waste of the talents of Deneuve and Auteuil.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Models"
      ],
      "metadata": {
        "id": "Cp0xV2cMVAp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "rDgpclcsXLTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.asarray(train_sequences).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hip8aJ3tyeEu",
        "outputId": "326cadd8-b5cf-4118-b957-22a1ce90d478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_sequences[0]))\n",
        "print(train_sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OudsnDKQyzev",
        "outputId": "2cd8264c-08bd-46b0-9f57-bf053e89705e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109\n",
            "[62, 4, 3, 129, 34, 44, 7576, 1414, 15, 3, 4252, 514, 43, 16, 3, 633, 133, 12, 6, 3, 1301, 459, 4, 1751, 209, 3, 10785, 7693, 308, 6, 676, 80, 32, 2137, 1110, 3008, 31, 1, 929, 4, 42, 5120, 469, 9, 2665, 1751, 1, 223, 55, 16, 54, 828, 1318, 847, 228, 9, 40, 96, 122, 1484, 57, 145, 36, 1, 996, 141, 27, 676, 122, 1, 13886, 411, 59, 94, 2278, 303, 772, 5, 3, 837, 11037, 20, 3, 1755, 646, 42, 125, 71, 22, 235, 101, 16, 46, 49, 624, 31, 702, 84, 702, 378, 3493, 12997, 2, 16816, 8422, 67, 27, 107, 3348]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_sequences[0]))\n",
        "print(test_sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-nSVoUIzgqG",
        "outputId": "6a76d0b1-4fbc-4f3a-d1b2-ee83b8d75a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164\n",
            "[277, 171, 440, 11801, 44, 3318, 43, 3, 17, 15, 227, 1203, 71, 1668, 1209, 36, 1, 1301, 2016, 2225, 842, 4, 60, 47, 23, 52, 168, 10, 40, 119, 21, 456, 41, 98, 4, 1, 102, 88, 4, 175, 25, 2750, 8, 1, 4229, 2, 106, 23, 1704, 399, 20, 2, 92, 1547, 363, 73, 300, 31, 60, 55, 10, 119, 21, 456, 1, 106, 72, 141, 63, 456, 41, 6, 3, 52, 9290, 13323, 15894, 1, 436, 6, 26, 263, 122, 14, 550, 34, 1287, 237, 125, 71, 256, 331, 184, 87, 2, 284, 54, 4084, 4, 3, 4229, 24, 61, 12103, 735, 5, 27, 1573, 117, 11801, 414, 51, 72, 23, 70, 498, 1, 317, 93, 210, 4, 11, 4228, 11801, 713, 175, 29, 41, 2750, 72, 23, 576, 135, 15894, 6, 2163, 5, 27, 1, 115, 16, 54, 2593, 16291, 39, 12063, 54, 1233, 130, 9, 13, 29, 10, 97, 78, 5, 398, 36, 1583, 9, 122, 32, 531, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFROcjV9zmqA",
        "outputId": "706e6782-6e64-438e-e633-e80c41987067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88582"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in word_index.items():\n",
        "  print(i, j)\n",
        "  if j == 20:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MteE3yYD2Y-m",
        "outputId": "43a4e6e6-f7d8-4194-d8ac-74e108665ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 1\n",
            "and 2\n",
            "a 3\n",
            "of 4\n",
            "to 5\n",
            "is 6\n",
            "br 7\n",
            "in 8\n",
            "it 9\n",
            "i 10\n",
            "this 11\n",
            "that 12\n",
            "was 13\n",
            "as 14\n",
            "for 15\n",
            "with 16\n",
            "movie 17\n",
            "but 18\n",
            "film 19\n",
            "on 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_valid_data = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_data = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "train_valid_labels = tf.keras.utils.to_categorical(np.asarray(train_labels))\n",
        "test_labels = tf.keras.utils.to_categorical(np.asarray(test_labels))"
      ],
      "metadata": {
        "id": "5hDvhwUxrUA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_valid_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtcwk2l13xBy",
        "outputId": "8b0ad1de-1364-47ec-ead5-a644955422a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_valid_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA-3VHWS44GC",
        "outputId": "db5faa32-7c84-4d9b-9760-a618b3897640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "          62,     4,     3,   129,    34,    44,  7576,  1414,    15,\n",
              "           3,  4252,   514,    43,    16,     3,   633,   133,    12,\n",
              "           6,     3,  1301,   459,     4,  1751,   209,     3, 10785,\n",
              "        7693,   308,     6,   676,    80,    32,  2137,  1110,  3008,\n",
              "          31,     1,   929,     4,    42,  5120,   469,     9,  2665,\n",
              "        1751,     1,   223,    55,    16,    54,   828,  1318,   847,\n",
              "         228,     9,    40,    96,   122,  1484,    57,   145,    36,\n",
              "           1,   996,   141,    27,   676,   122,     1, 13886,   411,\n",
              "          59,    94,  2278,   303,   772,     5,     3,   837, 11037,\n",
              "          20,     3,  1755,   646,    42,   125,    71,    22,   235,\n",
              "         101,    16,    46,    49,   624,    31,   702,    84,   702,\n",
              "         378,  3493, 12997,     2, 16816,  8422,    67,    27,   107,\n",
              "        3348], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsgMiRT939py",
        "outputId": "0de6b07e-905c-41ad-8f17-aa1345fe8056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_valid_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbVZ6d0H39nc",
        "outputId": "5b100050-3bbc-4a2a-cd92-0dd9700f1eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices =np.arange(train_valid_data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "train_valid_data = train_valid_data[indices]\n",
        "train_valid_labels = train_valid_labels[indices]\n",
        "num_validation_samples = int(VALIDATION_SPLIT * train_valid_data.shape[0])\n",
        "print(num_validation_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkd28yKKvDrV",
        "outputId": "d824310a-bb8b-41c1-9db7-6ca46fd986d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_valid_data[:-num_validation_samples]\n",
        "y_train = train_valid_labels[:-num_validation_samples]\n",
        "\n",
        "x_test = train_valid_data[-num_validation_samples:]\n",
        "y_test = train_valid_labels[-num_validation_samples:]"
      ],
      "metadata": {
        "id": "Ke0w8uzdvkJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), encoding='utf8') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs"
      ],
      "metadata": {
        "id": "ImEA8jYcwE5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index.get('attention')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CY-AmAR5-ui",
        "outputId": "49955c29-72b2-4a48-e40a-a7629e261382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.3414e-01,  4.6667e-01,  5.3744e-01,  5.7743e-02,  2.9642e-01,\n",
              "        2.5224e-01, -6.5586e-01, -4.1668e-01,  2.1959e-01, -4.9413e-01,\n",
              "       -2.1816e-01, -9.0227e-02, -3.5179e-02, -2.7279e-01, -1.2343e-01,\n",
              "        1.6808e-01, -5.0623e-01, -4.0497e-01, -1.6763e-01,  4.9066e-01,\n",
              "       -8.8020e-02, -1.2339e-01, -3.8436e-01, -2.7766e-01, -1.3403e-01,\n",
              "        1.4342e-01, -2.9177e-01, -2.1146e-02,  5.2180e-01, -2.1213e-01,\n",
              "        3.0860e-02,  1.0402e-01, -1.6807e-01,  4.6170e-01, -5.4806e-01,\n",
              "       -6.6849e-02, -3.3180e-01,  3.7257e-01, -7.4962e-01,  6.2741e-01,\n",
              "       -4.9500e-01, -4.0996e-01, -1.4686e-01, -2.7166e-01, -7.7093e-02,\n",
              "       -2.8342e-01,  6.3663e-02, -1.5734e-01,  6.9649e-01, -9.6694e-01,\n",
              "        4.4510e-01, -2.4521e-01, -4.8447e-01,  1.1957e+00,  2.9929e-02,\n",
              "       -2.0425e+00, -2.8603e-01, -3.9043e-01,  1.2197e+00, -4.7760e-01,\n",
              "       -2.1191e-02,  9.3080e-01, -1.8173e-01, -7.5721e-02,  1.1242e+00,\n",
              "       -8.2276e-02,  5.7149e-02, -2.3585e-01,  3.5901e-01,  6.9223e-01,\n",
              "        3.0860e-02, -2.6091e-01, -3.0284e-01, -3.9094e-01,  2.1887e-01,\n",
              "        3.7618e-01, -1.5990e-01, -2.7495e-01, -8.3322e-01, -1.7576e-01,\n",
              "        5.7404e-01, -3.6228e-01,  2.2346e-01, -4.6975e-01, -1.4354e+00,\n",
              "       -2.4484e-01, -6.6958e-01, -5.4293e-03, -5.7340e-01, -6.3122e-01,\n",
              "        9.8732e-03, -1.9317e-01,  3.0410e-01, -2.6329e-01, -1.0366e-03,\n",
              "        3.6515e-01, -9.3829e-02, -6.7265e-02,  5.9425e-01,  6.7652e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "  if i > MAX_NUM_WORDS:\n",
        "    continue\n",
        "  \n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "YO29tZMQwpti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(num_words, \n",
        "                                           EMBEDDING_DIM,\n",
        "                                           embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                                           input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                           trainable=False)"
      ],
      "metadata": {
        "id": "tdqribhVVAY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1D CNN"
      ],
      "metadata": {
        "id": "Ru-b9CDF_4_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = tf.keras.models.Sequential()\n",
        "cnn_model.add(embedding_layer)\n",
        "cnn_model.add(tf.keras.layers.Conv1D(128, 5, activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.MaxPool1D(5))\n",
        "cnn_model.add(tf.keras.layers.Conv1D(128, 5, activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.MaxPool1D(5))\n",
        "cnn_model.add(tf.keras.layers.Conv1D(128, 5, activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
        "cnn_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.Dense(len(labels_index), activation='relu'))"
      ],
      "metadata": {
        "id": "A8tL4N3JVAUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['acc'])"
      ],
      "metadata": {
        "id": "jmoJtwscVASV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.fit(x_train, y_train,\n",
        "              batch_size=32,\n",
        "              epochs=2,\n",
        "              validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EZ1tv1mVAP3",
        "outputId": "912307c8-a6e4-40a6-ca1c-7e97f1cd8b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "625/625 [==============================] - 173s 277ms/step - loss: nan - acc: 0.4975 - val_loss: nan - val_acc: 0.5100\n",
            "Epoch 2/2\n",
            "625/625 [==============================] - 171s 274ms/step - loss: nan - acc: 0.4975 - val_loss: nan - val_acc: 0.5100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f817b0809d0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score, acc = cnn_model.evaluate(test_data, test_labels)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EffQ_osQVANa",
        "outputId": "fbf565ae-8ebc-481f-c5a6-8343bc601e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LSTM Model"
      ],
      "metadata": {
        "id": "PdrMV3ZyKpFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####With Our Own Embedding Layer"
      ],
      "metadata": {
        "id": "55rfc8N5Wcd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = tf.keras.models.Sequential()\n",
        "rnn_model.add(tf.keras.layers.Embedding(MAX_NUM_WORDS, 128))\n",
        "rnn_model.add(tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "rnn_model.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
        "rnn_model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-3aXX9K-K1ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.fit(x_train, y_train,\n",
        "              batch_size=32, epochs=1,\n",
        "              validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "PZdscYDLK07R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score, acc = cnn_model.evaluate(test_data, test_labels)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "je4IiTlhWU4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####With Pre-trained Embedding Layer"
      ],
      "metadata": {
        "id": "PQT1-9l6WpN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = tf.keras.models.Sequential()\n",
        "rnn_model.add(embedding_layer)\n",
        "rnn_model.add(tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "rnn_model.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
        "rnn_model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aWORQX0CWvbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.fit(x_train, y_train,\n",
        "              batch_size=32, epochs=1,\n",
        "              validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlvk9mzzW5ze",
        "outputId": "3d2f8bc4-0115-411f-90d9-e365c1d048a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 1515s 2s/step - loss: 0.5762 - accuracy: 0.6996 - val_loss: 0.4493 - val_accuracy: 0.7978\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f718feab5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score, acc = rnn_model.evaluate(test_data, test_labels)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEsHVT6mXDdh",
        "outputId": "834b5cd6-69c8-44fb-d41c-d68ab99f2c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 244s 312ms/step - loss: 0.4492 - accuracy: 0.7976\n",
            "0.7976400256156921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BERT Sentiment Classification\n",
        "\n",
        "\n",
        "######On IMDB Reviews Dataset [kaggle](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)\n"
      ],
      "metadata": {
        "id": "nIvsHlIKO7Zn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###With pytorch_pretrained_bert"
      ],
      "metadata": {
        "id": "7rf5i9me0fSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/'\n",
        "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
        "!unzip \\*.zip && rm *.zip"
      ],
      "metadata": {
        "id": "K1eUnvH4JXIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification"
      ],
      "metadata": {
        "id": "mqhXfSu3rAq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "VxVfm0pDfUQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"IMDB Dataset.csv\",engine='python', error_bad_lines=False)"
      ],
      "metadata": {
        "id": "on8Akhy0h2OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Zox3B-Pkh4tW",
        "outputId": "83736d19-cbf9-4f55-a6ac-c561564544fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "49990  Lame, lame, lame!!! A 90-minute cringe-fest th...  negative\n",
              "49991  Les Visiteurs, the first movie about the medie...  negative\n",
              "49992  John Garfield plays a Marine who is blinded by...  positive\n",
              "49993  Robert Colomb has two full-time jobs. He's kno...  negative\n",
              "49994  This is your typical junk comedy.<br /><br />T...  negative\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb2646b5-bcce-4708-a62f-d817d48bc658\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49990</th>\n",
              "      <td>Lame, lame, lame!!! A 90-minute cringe-fest th...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49991</th>\n",
              "      <td>Les Visiteurs, the first movie about the medie...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49992</th>\n",
              "      <td>John Garfield plays a Marine who is blinded by...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49993</th>\n",
              "      <td>Robert Colomb has two full-time jobs. He's kno...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49994</th>\n",
              "      <td>This is your typical junk comedy.&lt;br /&gt;&lt;br /&gt;T...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb2646b5-bcce-4708-a62f-d817d48bc658')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb2646b5-bcce-4708-a62f-d817d48bc658 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb2646b5-bcce-4708-a62f-d817d48bc658');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'] = preprocessing.LabelEncoder().fit_transform(df.sentiment)"
      ],
      "metadata": {
        "id": "hP5YGiHTh7cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0aoxZfdZipPc",
        "outputId": "cf16d6d5-1700-41de-d059-900b78ac1d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8982d1c-e4f7-471b-9c8f-f287bf2dfbfa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8982d1c-e4f7-471b-9c8f-f287bf2dfbfa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8982d1c-e4f7-471b-9c8f-f287bf2dfbfa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8982d1c-e4f7-471b-9c8f-f287bf2dfbfa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3c1bQSFiprG",
        "outputId": "47b65f55-a22b-46d1-a90b-887b746c3fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    25000\n",
              "0    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def strip(text):\n",
        "  soup = bs4.BeautifulSoup(text, 'html.parser')\n",
        "  text = re.sub('\\[[^]]*\\]', '', soup.get_text())\n",
        "  pattern = r\"[^a-zA-Z0-9\\s,']\"\n",
        "  text = re.sub(pattern, '', text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "3yipGT9Si0bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in enumerate(zip(df.review, temp)):\n",
        "  if i == 5:\n",
        "    break\n",
        "  print(j[0], '\\n Changes to=====>\\n', j[1])\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6OM3JeilZdQ",
        "outputId": "a13f33d7-da7b-45a3-d3a6-e76c6d1746e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side. \n",
            " Changes to=====>\n",
            " One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked They are right, as this is exactly what happened with meThe first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO Trust me, this is not a show for the faint hearted or timid This show pulls no punches with regards to drugs, sex or violence Its is hardcore, in the classic use of the wordIt is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda Em City is home to manyAryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and moreso scuffles, death stares, dodgy dealings and shady agreements are never far awayI would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare Forget pretty pictures painted for mainstream audiences, forget charm, forget romanceOZ doesn't mess around The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence Not just violence, but injustice crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience Watching Oz, you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side\n",
            "\n",
            "\n",
            "A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done. \n",
            " Changes to=====>\n",
            " A wonderful little production The filming technique is very unassuming very oldtimeBBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece The actors are extremely well chosen Michael Sheen not only has got all the polari but he has all the voices down pat too You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece A masterful production about one of the great master's of comedy and his life The realism really comes home with the little things the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets particularly of their flat with Halliwell's murals decorating every surface are terribly well done\n",
            "\n",
            "\n",
            "I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends. \n",
            " Changes to=====>\n",
            " I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a lighthearted comedy The plot is simplistic, but the dialogue is witty and the characters are likable even the well bread suspected serial killer While some may be disappointed when they realize this is not Match Point 2 Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to loveThis was the most I'd laughed at one of Woody's comedies in years dare I say a decade While I've never been impressed with Scarlet Johanson, in this she managed to tone down her sexy image and jumped right into a average, but spirited young womanThis may not be the crown jewel of his career, but it was wittier than Devil Wears Prada and more interesting than Superman a great comedy to go see with friends\n",
            "\n",
            "\n",
            "Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them. \n",
            " Changes to=====>\n",
            " Basically there's a family where a little boy Jake thinks there's a zombie in his closet  his parents are fighting all the timeThis movie is slower than a soap opera and suddenly, Jake decides to become Rambo and kill the zombieOK, first of all when you're going to make a film you must Decide if its a thriller or a drama As a drama the movie is watchable Parents are divorcing  arguing like in real life And then we have Jake with his closet which totally ruins all the film I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots3 out of 10 just for the well playing parents  descent dialogs As for the shots with Jake just ignore them\n",
            "\n",
            "\n",
            "Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work. \n",
            " Changes to=====>\n",
            " Petter Mattei's Love in the Time of Money is a visually stunning film to watch Mr Mattei offers us a vivid portrait about human relations This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact Stylishly, the film has a sophisticated luxurious look We are taken to see how these people live and the world they live in their own habitatThe only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounterThe acting is good under Mr Mattei's direction Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come aliveWe wish Mr Mattei good luck and await anxiously for his next work\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df.review.apply(strip)"
      ],
      "metadata": {
        "id": "pBYzj6qplVd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ae6lD8YElnsr",
        "outputId": "34b31c65-56c8-4238-95f4-68ba64a2c481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production The filming tech...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's Love in the Time of Money is a...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c82e3eb-76ab-4cd9-b5f9-9d90c746a629\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production The filming tech...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's Love in the Time of Money is a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c82e3eb-76ab-4cd9-b5f9-9d90c746a629')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c82e3eb-76ab-4cd9-b5f9-9d90c746a629 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c82e3eb-76ab-4cd9-b5f9-9d90c746a629');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT expects a special token [CLS] to indicate the start of the sentence and   a special token [SEP] to indicate end of it."
      ],
      "metadata": {
        "id": "fWNjZGXymRAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [f'[CLS]{sen}[SEP]' for sen in df.review]"
      ],
      "metadata": {
        "id": "9F7foYfSmDqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer().from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenized_texts = list(map(lambda t: tokenizer.tokenize(t)[:510] , sentence))\n",
        "labels = list(df['sentiment'])"
      ],
      "metadata": {
        "id": "eWcoE703nWi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "input_ids = tf.keras.sequences.pad_sequences(list(map(tokenizer.convert_tokens_to_ids, tokenized_texts)),\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = tf.keras.sequences.pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "attention_masks = []\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)"
      ],
      "metadata": {
        "id": "l_eQ6WObnY7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = model_selection.train_test_split(input_ids, labels, \n",
        "                                                            random_state=65, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = model_selection.train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=65, test_size=0.1)\n",
        "                                             \n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "train_data = torch.utils.data.TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = torch.utils.data.RandomSampler(train_data)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
        "\n",
        "validation_data = torch.utils.data.TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = torch.utils.data.SequentialSampler(validation_data)\n",
        "validation_dataloader = torch.utils.data.DataLoader(validation_data, sampler=validation_sampler, batch_size=16)\n"
      ],
      "metadata": {
        "id": "ErAl-ri4pObE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "id": "ANI6hKePp0g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=2e-5,\n",
        "                     warmup=.1)\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "torch.cuda.empty_cache() \n",
        "train_loss_set = []\n",
        "epochs = 4\n",
        "\n",
        "for u in tqdm.trange(epochs, desc=\"Epoch\"):  \n",
        "  \n",
        "    model.train()  \n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        train_loss_set.append(loss.item())    \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "       \n",
        "\n",
        "    model.eval()\n",
        "    eval_accuracy = 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)    \n",
        "        \n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)    \n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n"
      ],
      "metadata": {
        "id": "z-TlHwZVp-6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###With Ktrain"
      ],
      "metadata": {
        "id": "EKod9xhr04Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\", \n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "    extract=True)\n",
        "\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")"
      ],
      "metadata": {
        "id": "BDmDNyzXp-0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test), preproc = ktrain.text.texts_from_folder(IMDB_DATADIR, \n",
        "                                                                       maxlen=500, \n",
        "                                                                       preprocess_mode='bert',\n",
        "                                                                       train_test_names=['train', 'test'],\n",
        "                                                                       classes=['pos', 'neg'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "pjEu-sIV1AYA",
        "outputId": "b5ada1dc-5f6b-4134-d9bb-cbd8c5ebb70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "detected encoding: utf-8\n",
            "preprocessing train...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = text.text_classifier('bert', (x_train, y_train), preproc=preproc)\n",
        "learner = ktrain.get_learner(model, train_data=(x_train, y_train), val_data=(x_test, y_test), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjn3dVwt1_ge",
        "outputId": "1de25f7e-8960-4cfa-9d6e-46a80b94978d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 500\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner.fit_onecycle(2e-5, 1)"
      ],
      "metadata": {
        "id": "V3lo-WTF2pCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Interpert a Deep Learning Model"
      ],
      "metadata": {
        "id": "TYmHsN6P8mBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data"
      ],
      "metadata": {
        "id": "cfODvwjTCHTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NUM_WORDS = 20000 \n",
        "EMBEDDING_DIM = 100 \n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "vocab_size = 20000  \n",
        "maxlen = 1000 "
      ],
      "metadata": {
        "id": "zQS_vOMFCxZz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper functions to lead the data\n",
        "def load_directory_data(directory):\n",
        "    data = {}\n",
        "    data[\"sentence\"] = []\n",
        "    data[\"sentiment\"] = []\n",
        "    for file_path in os.listdir(directory):\n",
        "        with tf.io.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "            data[\"sentence\"].append(f.read())\n",
        "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "    return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "    pos_df[\"polarity\"] = 1\n",
        "    neg_df[\"polarity\"] = 0\n",
        "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "def download_and_load_datasets(force_download=False):\n",
        "    dataset = tf.keras.utils.get_file(\n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "      extract=True)\n",
        "\n",
        "    train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "    test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "  \n",
        "    return train_df, test_df"
      ],
      "metadata": {
        "id": "urMIPzPg8mh1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('aclImdb'):\n",
        "    train,test = download_and_load_datasets()\n",
        "else:\n",
        "    train = load_dataset('aclImdb/train')\n",
        "    test = load_dataset('aclImdb/test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_soS8Zut88MP",
        "outputId": "77fff6f8-1e49-41fe-fe7a-b307d3f9a5f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 2s 0us/step\n",
            "84140032/84125825 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lime"
      ],
      "metadata": {
        "id": "_kqLExGBBTMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_texts = train['sentence'].values\n",
        "train_labels = train['polarity'].values\n",
        "\n",
        "test_texts = test['sentence'].values\n",
        "test_labels = test['polarity'].values\n",
        "\n",
        "labels_index = {'pos':1, 'neg':0} \n",
        "\n",
        "print(train.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feLfkHDH9ODx",
        "outputId": "d653b375-3681-4b12-9f39-e2c0eadd3b85"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['sentence', 'sentiment', 'polarity'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextsToSequences( tf.keras.preprocessing.text.Tokenizer, base.BaseEstimator, pipeline.TransformerMixin):\n",
        "    def __init__(self,  **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        \n",
        "    def fit(self, texts, y=None):\n",
        "        self.fit_on_texts(texts)\n",
        "        return self\n",
        "    \n",
        "    def transform(self, texts, y=None):\n",
        "        return np.array(self.texts_to_sequences(texts))\n",
        "        \n",
        "\n",
        "class Padder(base.BaseEstimator, pipeline.TransformerMixin):\n",
        "    def __init__(self, maxlen=500):\n",
        "        self.maxlen = maxlen\n",
        "        self.max_index = None\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        self.max_index = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=self.maxlen).max()\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=self.maxlen)\n",
        "        X[X > self.max_index] = 0\n",
        "        return X\n",
        "\n",
        "sequencer = TextsToSequences(num_words=vocab_size)\n",
        "padder = Padder(maxlen)"
      ],
      "metadata": {
        "id": "AcGRX52F9Z8n"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "max_features = vocab_size + 1\n",
        "\n",
        "def create_model(max_features):\n",
        "    rnnmodel = tf.keras.models.Sequential()\n",
        "    rnnmodel.add(tf.keras.layers.Embedding(MAX_NUM_WORDS, 128))\n",
        "    rnnmodel.add(tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    rnnmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "    rnnmodel.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "    return rnnmodel\n",
        "\n",
        "sklearn_lstm = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, epochs=1, batch_size=32, \n",
        "                               max_features=max_features, verbose=1)\n",
        "\n",
        "my_pipeline = pipeline.make_pipeline(sequencer, padder, sklearn_lstm)\n",
        "\n",
        "my_pipeline.fit(train_texts, train_labels)"
      ],
      "metadata": {
        "id": "JxkYcLBk92S2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = pipeline.predict(test_texts)"
      ],
      "metadata": {
        "id": "_81LOZzu-VeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "100 * metrics.accuracy_score(y_preds, test_labels)"
      ],
      "metadata": {
        "id": "wRwkpUAB-bHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 20\n",
        "text_sample = test_texts[idx]\n",
        "class_names = ['negative', 'positive']\n",
        "\n",
        "print('Sample {}: last 1000 words (only part used by the model)'.format(idx))\n",
        "print('-'*50)\n",
        "print(\" \".join(text_sample.split()[-1000:]))\n",
        "print('-'*50)\n",
        "print('Probability(positive) =', pipeline.predict_proba([text_sample])[0,1])\n",
        "print('True class: %s' % class_names[test_labels[idx]])"
      ],
      "metadata": {
        "id": "a1Q7wOdO-bDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from collections import OrderedDict\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n",
        "explanation = explainer.explain_instance(text_sample, pipeline.predict_proba, num_features=10)\n",
        "\n",
        "weights = OrderedDict(explanation.as_list())\n",
        "lime_weights = pd.DataFrame({'words': list(weights.keys()), 'weights': list(weights.values())})\n",
        "\n",
        "sns.barplot(x=\"words\", y=\"weights\", data=lime_weights);\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Sample {} features weights given by LIME'.format(idx));"
      ],
      "metadata": {
        "id": "gh1PtHuv-nKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Shap"
      ],
      "metadata": {
        "id": "qlYQE3x-BZuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts) #Converting text to a vector of word indexes\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "trainvalid_data = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_data = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "trainvalid_labels = tf.keras.utils.to_categorical(np.asarray(train_labels))\n",
        "test_labels = tf.keras.utils.to_categorical(np.asarray(test_labels))\n",
        "\n",
        "indices = np.arange(trainvalid_data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "trainvalid_data = trainvalid_data[indices]\n",
        "trainvalid_labels = trainvalid_labels[indices]\n",
        "num_validation_samples = int(VALIDATION_SPLIT * trainvalid_data.shape[0])\n",
        "\n",
        "x_train = trainvalid_data[:-num_validation_samples]\n",
        "y_train = trainvalid_labels[:-num_validation_samples]\n",
        "x_val = trainvalid_data[-num_validation_samples:]\n",
        "y_val = trainvalid_labels[-num_validation_samples:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epVi7IpiBv5T",
        "outputId": "296ef329-9dc9-4a64-fba5-1eae7c4cc89c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 88582 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(max_features):\n",
        "    rnnmodel = tf.keras.models.Sequential()\n",
        "    rnnmodel.add(tf.keras.layers.Embedding(MAX_NUM_WORDS, 128))\n",
        "    rnnmodel.add(tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    rnnmodel.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
        "    rnnmodel.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "    return rnnmodel\n",
        "\n",
        "sklearn_lstm = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, epochs=1, batch_size=32, \n",
        "                               max_features=max_features, verbose=1)\n",
        "\n",
        "my_pipeline = pipeline.make_pipeline(sequencer, padder, sklearn_lstm)\n",
        "\n",
        "my_pipeline.fit(train_texts, train_labels)\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "max_features = vocab_size + 1\n",
        "\n",
        "rnnmodel = tf.keras.models.Sequential()\n",
        "rnnmodel.add(tf.keras.layers.Embedding(MAX_NUM_WORDS, 128))\n",
        "rnnmodel.add(tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "rnnmodel.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
        "rnnmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "rnnmodel.fit(x_train, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=2,\n",
        "          validation_data=(x_val, y_val))\n",
        "score, acc = rnnmodel.evaluate(test_data, test_labels,\n",
        "                            batch_size=32)\n",
        "print('Test accuracy with RNN:', acc)"
      ],
      "metadata": {
        "id": "eOCm8Uv8ChoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "explainer = shap.DeepExplainer(rnnmodel, x_train[:20])\n",
        "\n",
        "shap_values = explainer.shap_values(x_val[:5])\n",
        "\n",
        "words = tf.keras.datasets.imdb.get_word_index()\n",
        "num2word = {}\n",
        "for w in words.keys():\n",
        "    num2word[words[w]] = w\n",
        "x_val_words = np.stack([np.array(list(map(lambda x: num2word.get(x, \"NONE\"), x_val[i]))) for i in range(10)])"
      ],
      "metadata": {
        "id": "zboqMck9DT5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value[0], shap_values[0][0], x_val_words[0])"
      ],
      "metadata": {
        "id": "W7IQ2t_RDjCJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WqulR4UnPROu",
        "Cp0xV2cMVAp6",
        "Ru-b9CDF_4_I",
        "PdrMV3ZyKpFW",
        "7rf5i9me0fSl"
      ],
      "name": "NLP_Text_Classification_DL.ipynb",
      "provenance": [],
      "mount_file_id": "1D3HsP6WtjHqSBHm1GR-6W5qJcLddLlR0",
      "authorship_tag": "ABX9TyOeOGhxS4nUN6eHjnX42nmD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}